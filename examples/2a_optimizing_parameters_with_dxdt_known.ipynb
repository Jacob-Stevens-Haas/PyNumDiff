{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Numerical differentiation of noisy data: Ground truth results\n",
    "\n",
    "This notebook builds on `1_basic_tutorial.ipynb` by calling optimization routines to find optimal parameters for each method.\n",
    "\n",
    "Some notes on notation and syntax:\n",
    "  * dt: (float) time step (note: we concentrated on differentiating timeseries data, however these functions work for a 1-dimensional spatial derivative as well)\n",
    "  * x: (np.array with length N) the time series you want to differentiate\n",
    "  * x_hat: (np.array like x) the smoothed estimate of x\n",
    "  * x_truth: (np.array like x) the true value of x (which is known when the data is simulated, and used for plotting purposes only)\n",
    "  * dxdt_hat: (np.array like x) the estimate of the derivative of x\n",
    "  * dxdt_truth: (np.array like x) the true value of dxdt (which is known when the data is simulated, and used for plotting purposes only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "# local import\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "    \n",
    "import pynumdiff\n",
    "\n",
    "simulate = pynumdiff.utils.simulate\n",
    "evaluate = pynumdiff.utils.evaluate\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Simulate some data\n",
    "\n",
    "pynumdiff comes with 6 different toy problems (choose the one that most resembles your data to see how the methods compare):\n",
    "* lorenz_x: (nonlinear) x component of a lorenz attractor\n",
    "* sine: (linear) sum of two sines\n",
    "* pop_dyn: (nonlinear) bounded exponential growth\n",
    "* triangle: (nonlinear) sharp-edged triangle wave with increasing frequency\n",
    "* pi_control: (linear / nonlinear) linear proportional integral controller with nonlinear control inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simulation parameters\n",
    "\n",
    "# noise is generated using np.random, e.g. np.random.normal, np.random.uniform, np.random.poisson\n",
    "# noise_type and noise_parameters should be compatible with np.random functions \n",
    "noise_type = 'normal'\n",
    "noise_parameters = [0, 0.01]\n",
    "\n",
    "# time step and time series length\n",
    "dt = 0.1 # sampling time step\n",
    "simdt = 0.01 # simulation timestep\n",
    "timeseries_length =  50 # sec\n",
    "problem = 'pi_control'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simulate data\n",
    "\n",
    "x, x_truth, dxdt_truth, extras = r = pynumdiff.utils.simulate.__dict__[problem](timeseries_length, \n",
    "                                                                                noise_parameters=noise_parameters, \n",
    "                                                                                dt=dt, \n",
    "                                                                                simdt=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For our toy problems we can optimize the parameters in one of two options:\n",
    "# 1. Use the known dxdt to find the best parameters \n",
    "# 2. Actual dxdt is unknown\n",
    "\n",
    "# In the real world, option (1) is not possible. \n",
    "\n",
    "# This notebook allows you to run the optimization with either option:\n",
    "# cheat=True selects option (1)\n",
    "# cheat=False selects option (2)\n",
    "\n",
    "cheat = True\n",
    "\n",
    "if cheat:\n",
    "    dxdt_truth_vals = dxdt_truth\n",
    "else:\n",
    "    dxdt_truth_vals = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The optimization approach described here solves a loss function that balances the faithfulness and smoothness of the derivative estimate, and relies on a single hyperparameter, $\\gamma$, or `tvgamma` in the code. See the paper for more detail, but a brief overview is given here.\n",
    "\n",
    "The loss function to find the optimal parameters is as follows,\n",
    "\n",
    "$$L = \\mbox{RMSE} \\bigg( \\mbox{trapz}(\\mathbf{\\hat{\\dot{x}}}(\\Phi)) + \\mu, \\mathbf{y} \\bigg) + \\gamma \\bigg({TV}\\big(\\mathbf{\\hat{\\dot{x}}}(\\Phi)\\big)\\bigg),$$\n",
    "where $\\mathbf{y}$ are the noisy measurements, \\mathbf{\\hat{\\dot{x}}} is the estimate of the derivative, $\\mbox{trapz}(\\cdot)$ is the discrete-time trapezoidal numerical integral, $\\mu$ resolves the unknown integration constant, \\\\(\\gamma\\\\) is a hyper-parameter, and $TV$ is the total variation,\n",
    "\n",
    "$$TV(\\mathbf{\\hat{\\dot{x}}}) = \\frac{1}{m}\\left\\lVert\\mathbf{\\hat{\\dot{x}}}_{0:m-1}-\\mathbf{\\hat{\\dot{x}}}_{1:m}\\right\\rVert_{1}.$$\n",
    "\n",
    "To use the code to  solve the loss function and find your optimal parameters is quite simple.\n",
    "\n",
    "First, find tvgamma using the following heuristic: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoff_frequency = 0.1 # high frequency of signal in the data\n",
    "log_gamma = -1.6*np.log(cutoff_frequency) -0.71*np.log(dt) - 5.1\n",
    "tvgamma = np.exp(log_gamma)      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, use the following syntax, as detailed in the notebook.\n",
    "\n",
    "    params, val = pynumdiff.optimize.sub_module.method(x, dt, params=None, \n",
    "                                                   tvgamma=tvgamma, # hyperparameter\n",
    "                                                   dxdt_truth=None, # no ground truth data\n",
    "                                                   options={})\n",
    "    print('Optimal parameters: ', params)\n",
    "    x_hat, dxdt_hat = pynumdiff.sub_module.method(x, dt, params, options={'smooth': True})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if cheat: # so the code doesn't break\n",
    "    tvgamma = 0 # since we are optimizing on the actual values, no need to regularize\n",
    "    \n",
    "print('tvgamma = ', tvgamma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Finite Difference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Finite Difference: First Order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_hat, dxdt_hat = pynumdiff.finite_difference.first_order(x, dt)\n",
    "evaluate.plot(x, dt, x_hat, dxdt_hat, x_truth, dxdt_truth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Finite Difference: Second Order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_hat, dxdt_hat = pynumdiff.finite_difference.first_order(x, dt)\n",
    "evaluate.plot(x, dt, x_hat, dxdt_hat, x_truth, dxdt_truth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Finite Difference: Iterated First Order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params, val = pynumdiff.optimize.finite_difference.first_order(x, dt, params=None, \n",
    "                                                               options={'iterate': True},\n",
    "                                                               tvgamma=tvgamma,\n",
    "                                                               dxdt_truth=dxdt_truth_vals)\n",
    "print('Optimal parameters: ', params)\n",
    "x_hat, dxdt_hat = pynumdiff.finite_difference.first_order(x, dt, params, options={'iterate': True})\n",
    "evaluate.plot(x, dt, x_hat, dxdt_hat, x_truth, dxdt_truth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Smooth Finite Difference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Smooth Finite Difference: Median smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params, val = pynumdiff.optimize.smooth_finite_difference.mediandiff(x, dt, params=None, \n",
    "                                                                     options={'iterate': True},\n",
    "                                                                     tvgamma=tvgamma,\n",
    "                                                                     dxdt_truth=dxdt_truth_vals)\n",
    "print('Optimal parameters: ', params)\n",
    "x_hat, dxdt_hat = pynumdiff.smooth_finite_difference.mediandiff(x, dt, params, options={'iterate': True})\n",
    "evaluate.plot(x, dt, x_hat, dxdt_hat, x_truth, dxdt_truth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Smooth Finite Difference: Mean smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params, val = pynumdiff.optimize.smooth_finite_difference.meandiff(x, dt, params=None, \n",
    "                                                                   options={'iterate': True},\n",
    "                                                                   tvgamma=tvgamma,\n",
    "                                                                     dxdt_truth=dxdt_truth_vals)\n",
    "print('Optimal parameters: ', params)\n",
    "x_hat, dxdt_hat = pynumdiff.smooth_finite_difference.meandiff(x, dt, params, options={'iterate': True})\n",
    "evaluate.plot(x, dt, x_hat, dxdt_hat, x_truth, dxdt_truth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Smooth Finite Difference: Gaussian smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params, val = pynumdiff.optimize.smooth_finite_difference.gaussiandiff(x, dt, params=None, \n",
    "                                                                       options={'iterate': True},\n",
    "                                                                       tvgamma=tvgamma,\n",
    "                                                                     dxdt_truth=dxdt_truth_vals)\n",
    "print('Optimal parameters: ', params)\n",
    "x_hat, dxdt_hat = pynumdiff.smooth_finite_difference.gaussiandiff(x, dt, params, options={'iterate': True})\n",
    "evaluate.plot(x, dt, x_hat, dxdt_hat, x_truth, dxdt_truth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Smooth Finite Difference: Friedrichs smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params, val = pynumdiff.optimize.smooth_finite_difference.friedrichsdiff(x, dt, params=None, \n",
    "                                                                         options={'iterate': True},\n",
    "                                                                         tvgamma=tvgamma,\n",
    "                                                                     dxdt_truth=dxdt_truth_vals)\n",
    "print('Optimal parameters: ', params)\n",
    "x_hat, dxdt_hat = pynumdiff.smooth_finite_difference.friedrichsdiff(x, dt, params, options={'iterate': True})\n",
    "evaluate.plot(x, dt, x_hat, dxdt_hat, x_truth, dxdt_truth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 Smooth Finite Difference: Butterworth smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params, val = pynumdiff.optimize.smooth_finite_difference.butterdiff(x, dt, params=None, \n",
    "                                                                     options={'iterate': True},\n",
    "                                                                     tvgamma=tvgamma,\n",
    "                                                                     dxdt_truth=dxdt_truth_vals)\n",
    "print('Optimal parameters: ', params)\n",
    "x_hat, dxdt_hat = pynumdiff.smooth_finite_difference.butterdiff(x, dt, params, options={'iterate': True})\n",
    "evaluate.plot(x, dt, x_hat, dxdt_hat, x_truth, dxdt_truth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.6 Smooth Finite Difference: Spline smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params, val = pynumdiff.optimize.smooth_finite_difference.splinediff(x, dt, params=None, \n",
    "                                                                     options={'iterate': True},\n",
    "                                                                     tvgamma=tvgamma,\n",
    "                                                                     dxdt_truth=dxdt_truth_vals)\n",
    "print('Optimal parameters: ', params)\n",
    "x_hat, dxdt_hat = pynumdiff.smooth_finite_difference.splinediff(x, dt, params, options={'iterate': True})\n",
    "evaluate.plot(x, dt, x_hat, dxdt_hat, x_truth, dxdt_truth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Total Variation Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Iterative Total Variation Regularization (regularized velocity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params, val = pynumdiff.optimize.total_variation_regularization.iterative_velocity(x, dt, params=None, \n",
    "                                                                                   tvgamma=tvgamma,\n",
    "                                                                                   dxdt_truth=dxdt_truth_vals)\n",
    "print('Optimal parameters: ', params)\n",
    "x_hat, dxdt_hat = pynumdiff.total_variation_regularization.iterative_velocity(x, dt, params)\n",
    "evaluate.plot(x, dt, x_hat, dxdt_hat, x_truth, dxdt_truth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Convex Total Variation Regularization: regularize velocity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params, val = pynumdiff.optimize.total_variation_regularization.velocity(x, dt, params=None, \n",
    "                                                                         tvgamma=tvgamma,\n",
    "                                                                         dxdt_truth=dxdt_truth_vals)\n",
    "print('Optimal parameters: ', params)\n",
    "x_hat, dxdt_hat = pynumdiff.total_variation_regularization.velocity(x, dt, params)\n",
    "evaluate.plot(x, dt, x_hat, dxdt_hat, x_truth, dxdt_truth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Convex Total Variation Regularization: regularize acceleration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "params, val = pynumdiff.optimize.total_variation_regularization.acceleration(x, dt, params=None, \n",
    "                                                                             tvgamma=tvgamma,\n",
    "                                                                             dxdt_truth=dxdt_truth_vals)\n",
    "print('Optimal parameters: ', params)\n",
    "x_hat, dxdt_hat = pynumdiff.total_variation_regularization.acceleration(x, dt, params)\n",
    "evaluate.plot(x, dt, x_hat, dxdt_hat, x_truth, dxdt_truth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Convex Total Variation Regularization: regularize jerk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "params, val = pynumdiff.optimize.total_variation_regularization.jerk(x, dt, params=None, \n",
    "                                                                     tvgamma=tvgamma,\n",
    "                                                                    dxdt_truth=dxdt_truth_vals)\n",
    "print('Optimal parameters: ', params)\n",
    "x_hat, dxdt_hat = pynumdiff.total_variation_regularization.jerk(x, dt, params)\n",
    "evaluate.plot(x, dt, x_hat, dxdt_hat, x_truth, dxdt_truth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 Convex Total Variation Regularization: regularize acceleration with gaussian smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params, val = pynumdiff.optimize.total_variation_regularization.smooth_acceleration(x, dt, params=None, \n",
    "                                                                             tvgamma=tvgamma,\n",
    "                                                                             dxdt_truth=dxdt_truth_vals)\n",
    "print('Optimal parameters: ', params)\n",
    "x_hat, dxdt_hat = pynumdiff.total_variation_regularization.smooth_acceleration(x, dt, params)\n",
    "evaluate.plot(x, dt, x_hat, dxdt_hat, x_truth, dxdt_truth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Linear Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Linear Models: Spectral derivative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "params, val = pynumdiff.optimize.linear_model.spectraldiff(x, dt, params=None, \n",
    "                                                           tvgamma=tvgamma,\n",
    "                                                                     dxdt_truth=dxdt_truth_vals)\n",
    "print('Optimal parameters: ', params)\n",
    "x_hat, dxdt_hat = pynumdiff.linear_model.spectraldiff(x, dt, params)\n",
    "evaluate.plot(x, dt, x_hat, dxdt_hat, x_truth, dxdt_truth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Linear Models: Sliding polynomial fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "params, val = pynumdiff.optimize.linear_model.polydiff(x, dt, params=None, \n",
    "                                                       tvgamma=tvgamma,\n",
    "                                                                     dxdt_truth=dxdt_truth_vals)\n",
    "print('Optimal parameters: ', params)\n",
    "x_hat, dxdt_hat = pynumdiff.linear_model.polydiff(x, dt, params)\n",
    "evaluate.plot(x, dt, x_hat, dxdt_hat, x_truth, dxdt_truth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Linear Models: Savitzky-Golay filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params, val = pynumdiff.optimize.linear_model.savgoldiff(x, dt, params=None, \n",
    "                                                         tvgamma=tvgamma,\n",
    "                                                         dxdt_truth=dxdt_truth_vals,\n",
    "                                                         options={'smooth': True})\n",
    "print('Optimal parameters: ', params)\n",
    "x_hat, dxdt_hat = pynumdiff.linear_model.savgoldiff(x, dt, params, options={'smooth': True})\n",
    "evaluate.plot(x, dt, x_hat, dxdt_hat, x_truth, dxdt_truth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Linear Models: Sliding chebychev polynomial fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params, val = pynumdiff.optimize.linear_model.chebydiff(x, dt, params=None, \n",
    "                                                        tvgamma=tvgamma,\n",
    "                                                                     dxdt_truth=dxdt_truth_vals)\n",
    "print('Optimal parameters: ', params)\n",
    "x_hat, dxdt_hat = pynumdiff.linear_model.chebydiff(x, dt, params)\n",
    "evaluate.plot(x, dt, x_hat, dxdt_hat, x_truth, dxdt_truth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5 Linear Models: Sliding dynamic mode decomposition fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 0: # this one is too slow!\n",
    "    params, val = pynumdiff.optimize.linear_model.dmddiff(x, dt, params=None, \n",
    "                                                           tvgamma=tvgamma,\n",
    "                                                          dxdt_truth=dxdt_truth_vals)\n",
    "    print('Optimal parameters: ', params)\n",
    "    x_hat, dxdt_hat = pynumdiff.linear_model.dmddiff(x, dt, params)\n",
    "    evaluate.plot(x, dt, x_hat, dxdt_hat, x_truth, dxdt_truth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.6 Linear Models: Sliding linear time invariant system fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if 0: # this one is too slow!\n",
    "    params, val = pynumdiff.optimize.linear_model.lineardiff(x, dt, params=None, \n",
    "                                                             tvgamma=tvgamma,\n",
    "                                                                         dxdt_truth=dxdt_truth_vals)\n",
    "    print('Optimal parameters: ', params)\n",
    "    x_hat, dxdt_hat = pynumdiff.linear_model.lineardiff(x, dt, params)\n",
    "    evaluate.plot(x, dt, x_hat, dxdt_hat, x_truth, dxdt_truth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kalman smoothing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Kalman smoothing: constant velocity (forward-backward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "params, val = pynumdiff.optimize.kalman_smooth.constant_velocity(x, dt, params=None, \n",
    "                                                                 tvgamma=tvgamma,\n",
    "                                                                     dxdt_truth=dxdt_truth_vals)\n",
    "print('Optimal parameters: ', params)\n",
    "x_hat, dxdt_hat = pynumdiff.kalman_smooth.constant_velocity(x, dt, params)\n",
    "evaluate.plot(x, dt, x_hat, dxdt_hat, x_truth, dxdt_truth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Kalman smoothing: constant acceleration (forward-backward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "params, val = pynumdiff.optimize.kalman_smooth.constant_acceleration(x, dt, params=None, \n",
    "                                                                 tvgamma=tvgamma,\n",
    "                                                                    dxdt_truth=dxdt_truth_vals)\n",
    "print('Optimal parameters: ', params)\n",
    "x_hat, dxdt_hat = pynumdiff.kalman_smooth.constant_acceleration(x, dt, params)\n",
    "evaluate.plot(x, dt, x_hat, dxdt_hat, x_truth, dxdt_truth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Kalman smoothing: constant jerk (forward-backward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params, val = pynumdiff.optimize.kalman_smooth.constant_jerk(x, dt, params=None, \n",
    "                                                                 tvgamma=tvgamma,\n",
    "                                                                     dxdt_truth=dxdt_truth_vals)\n",
    "print('Optimal parameters: ', params)\n",
    "x_hat, dxdt_hat = pynumdiff.kalman_smooth.constant_jerk(x, dt, params)\n",
    "evaluate.plot(x, dt, x_hat, dxdt_hat, x_truth, dxdt_truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
